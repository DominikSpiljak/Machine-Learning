{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sveučilište u Zagrebu  \n",
    "Fakultet elektrotehnike i računarstva  \n",
    "  \n",
    "## Strojno učenje 2020/2021  \n",
    "http://www.fer.unizg.hr/predmet/su"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "\n",
    "### Laboratorijska vježba 1: Regresija\n",
    "\n",
    "*Verzija: 1.3  \n",
    "Zadnji put ažurirano: 6. 10. 2020.*\n",
    "\n",
    "(c) 2015-2020 Jan Šnajder, Domagoj Alagić \n",
    "\n",
    "Rok za predaju: **19. 10. 2020. u 06:00h**\n",
    "\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upute\n",
    "\n",
    "Prva laboratorijska vježba sastoji se od osam zadataka. U nastavku slijedite upute navedene u ćelijama s tekstom. Rješavanje vježbe svodi se na **dopunjavanje ove bilježnice**: umetanja ćelije ili više njih **ispod** teksta zadatka, pisanja odgovarajućeg kôda te evaluiranja ćelija. \n",
    "\n",
    "Osigurajte da u potpunosti **razumijete** kôd koji ste napisali. Kod predaje vježbe, morate biti u stanju na zahtjev asistenta (ili demonstratora) preinačiti i ponovno evaluirati Vaš kôd. Nadalje, morate razumjeti teorijske osnove onoga što radite, u okvirima onoga što smo obradili na predavanju. Ispod nekih zadataka možete naći i pitanja koja služe kao smjernice za bolje razumijevanje gradiva (**nemojte pisati** odgovore na pitanja u bilježnicu). Stoga se nemojte ograničiti samo na to da riješite zadatak, nego slobodno eksperimentirajte. To upravo i jest svrha ovih vježbi.\n",
    "\n",
    "Vježbe trebate raditi **samostalno** ili u **tandemu**. Možete se konzultirati s drugima o načelnom načinu rješavanja, ali u konačnici morate sami odraditi vježbu. U protivnome vježba nema smisla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Učitaj osnovne biblioteke...\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadatci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Jednostavna regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadan je skup primjera $\\mathcal{D}=\\{(x^{(i)},y^{(i)})\\}_{i=1}^4 = \\{(0,4),(1,1),(2,2),(4,5)\\}$. Primjere predstavite matricom $\\mathbf{X}$ dimenzija $N\\times n$ (u ovom slučaju $4\\times 1$) i vektorom oznaka $\\textbf{y}$, dimenzija $N\\times 1$ (u ovom slučaju $4\\times 1$), na sljedeći način:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0],[1],[2],[4]])\n",
    "y = np.array([4,1,2,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Proučite funkciju [`PolynomialFeatures`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) iz biblioteke `sklearn` i upotrijebite je za generiranje matrice dizajna $\\mathbf{\\Phi}$ koja ne koristi preslikavanje u prostor više dimenzije (samo će svakom primjeru biti dodane *dummy* jedinice; $m=n+1$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(1)\n",
    "X_tilda = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upoznajte se s modulom [`linalg`](http://docs.scipy.org/doc/numpy/reference/routines.linalg.html). Izračunajte težine $\\mathbf{w}$ modela linearne regresije kao $\\mathbf{w}=(\\mathbf{\\Phi}^\\intercal\\mathbf{\\Phi})^{-1}\\mathbf{\\Phi}^\\intercal\\mathbf{y}$. Zatim se uvjerite da isti rezultat možete dobiti izračunom pseudoinverza $\\mathbf{\\Phi}^+$ matrice dizajna, tj. $\\mathbf{w}=\\mathbf{\\Phi}^+\\mathbf{y}$, korištenjem funkcije [`pinv`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.pinv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.2        0.45714286]\n",
      "[2.2        0.45714286]\n"
     ]
    }
   ],
   "source": [
    "from numpy import linalg\n",
    "w = linalg.inv(X_tilda.T.dot(X_tilda)).dot(X_tilda.T).dot(y)\n",
    "print(w)\n",
    "w1 = linalg.pinv(X_tilda).dot(y)\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radi jasnoće, u nastavku je vektor $\\mathbf{x}$ s dodanom *dummy* jedinicom $x_0=1$ označen kao $\\tilde{\\mathbf{x}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prikažite primjere iz $\\mathcal{D}$ i funkciju $h(\\tilde{\\mathbf{x}})=\\mathbf{w}^\\intercal\\tilde{\\mathbf{x}}$. Izračunajte pogrešku učenja prema izrazu $E(h|\\mathcal{D})=\\frac{1}{2}\\sum_{i=1}^N(\\tilde{\\mathbf{y}}^{(i)} - h(\\tilde{\\mathbf{x}}^{(i)}))^2$. Možete koristiti funkciju srednje kvadratne pogreške [`mean_squared_error`]( http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) iz modula [`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics).\n",
    "\n",
    "**Q:** Gore definirana funkcija pogreške $E(h|\\mathcal{D})$ i funkcija srednje kvadratne pogreške nisu posve identične. U čemu je razlika? Koja je \"realnija\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.085714285714285\n",
      "2.0428571428571427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "h = w.dot(X_tilda.T)\n",
    "ehd = 1/2 * np.sum(np.square(y - h))\n",
    "mse = mean_squared_error(y, h)\n",
    "print(ehd)\n",
    "print(mse)\n",
    "print('Funkcija srednje kvadratne pogreške je realnija jer gleda prosječan gubitak po primjerim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uvjerite se da za primjere iz $\\mathcal{D}$ težine $\\mathbf{w}$ ne možemo naći rješavanjem sustava $\\mathbf{w}=\\mathbf{\\Phi}^{-1}\\mathbf{y}$, već da nam doista treba pseudoinverz.\n",
    "\n",
    "**Q:** Zašto je to slučaj? Bi li se problem mogao riješiti preslikavanjem primjera u višu dimenziju? Ako da, bi li to uvijek funkcioniralo, neovisno o skupu primjera $\\mathcal{D}$? Pokažite na primjeru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinAlgError: Last 2 dimensions of the array must be square\n",
      "X nije kvadratna matrica\n",
      "LinAlgError: Singular matrix\n",
      "Matrica je singularna\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    w = linalg.inv(X_tilda).dot(y)\n",
    "except LinAlgError as e:\n",
    "    print('LinAlgError: {}'.format(e))\n",
    "    print('X nije kvadratna matrica')\n",
    "\n",
    "square_matrix =  np.array([[0, 2, -1],[3, -2, 1],[3, 2, -1]])\n",
    "\n",
    "try:\n",
    "    w = linalg.inv(square_matrix).dot(y)\n",
    "except LinAlgError as e:\n",
    "    print('LinAlgError: {}'.format(e))\n",
    "    print('Matrica je singularna')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proučite klasu [`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) iz modula [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model). Provjerite jesu li težine koje izračunava ta funkcija (dostupne pomoću atributa `coef_` i `intercept_`) jednake onima koje ste izračunali gore. Ako nisu, prilagodite kôd tako da jest.\n",
    "\n",
    "**NB:** Obratite pozornost na to kako klase [`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) i [`PolynomialFeatures`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) koriste pomak i osigurajte da ga ne dodajete više puta.\n",
    "\n",
    "Izračunajte predikcije modela (metoda `predict`) i uvjerite se da je pogreška učenja identična onoj koju ste ranije izračunali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2 [0.         0.45714286]\n",
      "2.042857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_tilda, y)\n",
    "print(reg.intercept_, reg.coef_)\n",
    "\n",
    "pred = reg.predict(X_tilda)\n",
    "print(mean_squared_error(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Polinomijalna regresija i utjecaj šuma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Razmotrimo sada regresiju na većem broju primjera. Definirajte funkciju `make_labels(X, f, noise=0)` koja uzima matricu neoznačenih primjera $\\mathbf{X}_{N\\times n}$ te generira vektor njihovih oznaka $\\mathbf{y}_{N\\times 1}$. Oznake se generiraju kao $y^{(i)} = f(x^{(i)})+\\mathcal{N}(0,\\sigma^2)$, gdje je $f:\\mathbb{R}^n\\to\\mathbb{R}$ stvarna funkcija koja je generirala podatke (koja nam je u stvarnosti nepoznata), a $\\sigma$ je standardna devijacija Gaussovog šuma, definirana parametrom `noise`. Za generiranje šuma možete koristiti funkciju [`numpy.random.normal`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html). \n",
    "\n",
    "Generirajte skup za učenje od $N=50$ primjera uniformno distribuiranih u intervalu $[-5,5]$ pomoću funkcije $f(x) = 5 + x -2 x^2 -5 x^3$ uz šum  $\\sigma=200$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import normal\n",
    "def make_labels(X, f, noise=0):\n",
    "    return np.array([f(x_) + normal(0, noise, 1) for x_ in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_instances(x1, x2, N) :\n",
    "    return np.array([np.array([x]) for x in np.linspace(x1,x2,N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = make_instances(-5, 5, 50)\n",
    "y = make_labels(X, lambda x: 5 + x - 2 * x ** 2 - 5 * x ** 3, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prikažite taj skup funkcijom [`scatter`](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenirajte model polinomijalne regresije stupnja $d=3$. Na istom grafikonu prikažite naučeni model $h(\\mathbf{x})=\\mathbf{w}^\\intercal\\tilde{\\mathbf{x}}$ i primjere za učenje. Izračunajte pogrešku učenja modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53380.53344896717\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "X_tilda = poly.fit_transform(X)\n",
    "w = linalg.pinv(X_tilda).dot(y)\n",
    "preds = w.T.dot(X_tilda.T)\n",
    "\n",
    "print(mean_squared_error(y, preds.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Odabir modela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Na skupu podataka iz zadatka 2 trenirajte pet modela linearne regresije $\\mathcal{H}_d$ različite složenosti, gdje je $d$ stupanj polinoma, $d\\in\\{1,3,5,10,20\\}$. Prikažite na istome grafikonu skup za učenje i funkcije $h_d(\\mathbf{x})$ za svih pet modela (preporučujemo koristiti `plot` unutar `for` petlje). Izračunajte pogrešku učenja svakog od modela.\n",
    "\n",
    "**Q:** Koji model ima najmanju pogrešku učenja i zašto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61039.65336430831\n",
      "53380.53344896717\n",
      "44230.34919908545\n",
      "40616.57629167557\n",
      "35475.84655612068\n"
     ]
    }
   ],
   "source": [
    "plt.scatter(X, y)\n",
    "\n",
    "for d in [0, 2, 4, 9, 19]:\n",
    "    if d == 0:\n",
    "        X_tilda = X\n",
    "    else:\n",
    "        poly = PolynomialFeatures(d)\n",
    "        X_tilda = poly.fit_transform(X)\n",
    "    w = linalg.pinv(X_tilda).dot(y)\n",
    "    preds = w.T.dot(X_tilda.T)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Razdvojite skup primjera iz zadatka 2 pomoću funkcije [`model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) na skup za učenja i skup za ispitivanje u omjeru 1:1. Prikažite na jednom grafikonu pogrešku učenja i ispitnu pogrešku za modele polinomijalne regresije $\\mathcal{H}_d$, sa stupnjem polinoma $d$ u rasponu $d\\in [1,2,\\ldots,20]$. Budući da kvadratna pogreška brzo raste za veće stupnjeve polinoma, umjesto da iscrtate izravno iznose pogrešaka, iscrtajte njihove logaritme.\n",
    "\n",
    "**NB:** Podjela na skupa za učenje i skup za ispitivanje mora za svih pet modela biti identična.\n",
    "\n",
    "**Q:** Je li rezultat u skladu s očekivanjima? Koji biste model odabrali i zašto?\n",
    "\n",
    "**Q:** Pokrenite iscrtavanje više puta. U čemu je problem? Bi li problem bio jednako izražen kad bismo imali više primjera? Zašto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Točnost modela ovisi o (1) njegovoj složenosti (stupanj $d$ polinoma), (2) broju primjera $N$, i (3) količini šuma. Kako biste to analizirali, nacrtajte grafikone pogrešaka kao u 3b, ali za različit $N\\in$ (trećina, dvije trećine, sve) i količine šuma $\\sigma\\in\\{100,200,500\\}$ (ukupno 9 grafikona). Upotrijebite funkciju [`subplots`](http://matplotlib.org/examples/pylab_examples/subplots_demo.html) kako biste pregledno posložili grafikone u tablicu $3\\times 3$. Podatci se generiraju na isti način kao u zadatku 2.\n",
    "\n",
    "**NB:** Pobrinite se da svi grafikoni budu generirani nad usporedivim skupovima podataka, na sljedeći način. Generirajte najprije svih 1000 primjera, podijelite ih na skupove za učenje i skupove za ispitivanje (dva skupa od po 500 primjera). Zatim i od skupa za učenje i od skupa za ispitivanje načinite tri različite verzije, svaka s drugačijom količinom šuma (ukupno 2x3=6 verzija podataka). Kako bi simulirali veličinu skupa podataka, od tih dobivenih 6 skupova podataka uzorkujte trećinu, dvije trećine i sve podatke. Time ste dobili 18 skupova podataka -- skup za učenje i za testiranje za svaki od devet grafova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q:*** Jesu li rezultati očekivani? Obrazložite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Regularizirana regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "U gornjim eksperimentima nismo koristili **regularizaciju**. Vratimo se najprije na primjer iz zadatka 1. Na primjerima iz tog zadatka izračunajte težine $\\mathbf{w}$ za polinomijalni regresijski model stupnja $d=3$ uz L2-regularizaciju (tzv. *ridge regression*), prema izrazu $\\mathbf{w}=(\\mathbf{\\Phi}^\\intercal\\mathbf{\\Phi}+\\lambda\\mathbf{I})^{-1}\\mathbf{\\Phi}^\\intercal\\mathbf{y}$. Napravite izračun težina za regularizacijske faktore $\\lambda=0$, $\\lambda=1$ i $\\lambda=10$ te usporedite dobivene težine.\n",
    "\n",
    "**Q:** Kojih je dimenzija matrica koju treba invertirati?\n",
    "\n",
    "**Q:** Po čemu se razlikuju dobivene težine i je li ta razlika očekivana? Obrazložite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proučite klasu [`Ridge`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) iz modula [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model), koja implementira L2-regularizirani regresijski model. Parametar $\\alpha$ odgovara parametru $\\lambda$. Primijenite model na istim primjerima kao u prethodnom zadatku i ispišite težine $\\mathbf{w}$ (atributi `coef_` i `intercept_`). Ponovno, pripazite na pomak.\n",
    "\n",
    "**Q:** Jesu li težine identične onima iz zadatka 4a? Ako nisu, objasnite zašto je to tako i kako biste to popravili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Regularizirana polinomijalna regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Vratimo se na slučaj $N=50$ slučajno generiranih primjera iz zadatka 2. Trenirajte modele polinomijalne regresije $\\mathcal{H}_{\\lambda,d}$ za $\\lambda\\in\\{0,100\\}$ i $d\\in\\{2,10\\}$ (ukupno četiri modela). Skicirajte pripadne funkcije $h(\\mathbf{x})$ i primjere (na jednom grafikonu; preporučujemo koristiti `plot` unutar `for` petlje).\n",
    "\n",
    "**Q:** Jesu li rezultati očekivani? Obrazložite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)\n",
    "\n",
    "Kao u zadataku 3b, razdvojite primjere na skup za učenje i skup za ispitivanje u omjeru 1:1. Prikažite krivulje logaritama pogreške učenja i ispitne pogreške u ovisnosti za model $\\mathcal{H}_{d=10,\\lambda}$, podešavajući faktor regularizacije $\\lambda$ u rasponu $\\lambda\\in\\{0,1,\\dots,50\\}$.\n",
    "\n",
    "**Q:** Kojoj strani na grafikonu odgovara područje prenaučenosti, a kojoj podnaučenosti? Zašto?\n",
    "\n",
    "**Q:** Koju biste vrijednosti za $\\lambda$ izabrali na temelju ovih grafikona i zašto?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. L1-regularizacija i L2-regularizacija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svrha regularizacije jest potiskivanje težina modela $\\mathbf{w}$ prema nuli, kako bi model bio što jednostavniji. Složenost modela može se okarakterizirati normom pripadnog vektora težina $\\mathbf{w}$, i to tipično L2-normom ili L1-normom. Za jednom trenirani model možemo izračunati i broj ne-nul značajki, ili L0-normu, pomoću sljedeće funkcije koja prima vektor težina $\\mathbf{w}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonzeroes(coef, tol=1e-6): \n",
    "    return len(coef) - len(coef[np.isclose(0, coef, atol=tol)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Za ovaj zadatak upotrijebite skup za učenje i skup za testiranje iz zadatka 3b. Trenirajte modele **L2-regularizirane** polinomijalne regresije stupnja $d=5$, mijenjajući hiperparametar $\\lambda$ u rasponu $\\{1,2,\\dots,100\\}$. Za svaki od treniranih modela izračunajte L{0,1,2}-norme vektora težina $\\mathbf{w}$ te ih prikažite kao funkciju od $\\lambda$. Pripazite što točno šaljete u funkciju za izračun normi.\n",
    "\n",
    "**Q:** Objasnite oblik obiju krivulja. Hoće li krivulja za $\\|\\mathbf{w}\\|_2$ doseći nulu? Zašto? Je li to problem? Zašto?\n",
    "\n",
    "**Q:** Za $\\lambda=100$, koliki je postotak težina modela jednak nuli, odnosno koliko je model rijedak?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glavna prednost L1-regularizirane regresije (ili *LASSO regression*) nad L2-regulariziranom regresijom jest u tome što L1-regularizirana regresija rezultira **rijetkim modelima** (engl. *sparse models*), odnosno modelima kod kojih su mnoge težine pritegnute na nulu. Pokažite da je to doista tako, ponovivši gornji eksperiment s **L1-regulariziranom** regresijom, implementiranom u klasi  [`Lasso`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) u modulu [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Značajke različitih skala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Često se u praksi možemo susreti sa podatcima u kojima sve značajke nisu jednakih magnituda. Primjer jednog takvog skupa je regresijski skup podataka `grades` u kojem se predviđa prosjek ocjena studenta na studiju (1--5) na temelju dvije značajke: bodova na prijamnom ispitu (1--3000) i prosjeka ocjena u srednjoj školi. Prosjek ocjena na studiju izračunat je kao težinska suma ove dvije značajke uz dodani šum.\n",
    "\n",
    "Koristite sljedeći kôd kako biste generirali ovaj skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data_points = 500\n",
    "np.random.seed(69)\n",
    "\n",
    "# Generiraj podatke o bodovima na prijamnom ispitu koristeći normalnu razdiobu i ograniči ih na interval [1, 3000].\n",
    "exam_score = np.random.normal(loc=1500.0, scale = 500.0, size = n_data_points) \n",
    "exam_score = np.round(exam_score)\n",
    "exam_score[exam_score > 3000] = 3000\n",
    "exam_score[exam_score < 0] = 0\n",
    "\n",
    "# Generiraj podatke o ocjenama iz srednje škole koristeći normalnu razdiobu i ograniči ih na interval [1, 5].\n",
    "grade_in_highschool = np.random.normal(loc=3, scale = 2.0, size = n_data_points)\n",
    "grade_in_highschool[grade_in_highschool > 5] = 5\n",
    "grade_in_highschool[grade_in_highschool < 1] = 1\n",
    "\n",
    "# Matrica dizajna.\n",
    "grades_X = np.array([exam_score,grade_in_highschool]).T\n",
    "\n",
    "# Završno, generiraj izlazne vrijednosti.\n",
    "rand_noise = np.random.normal(loc=0.0, scale = 0.5, size = n_data_points)\n",
    "exam_influence = 0.9\n",
    "grades_y = ((exam_score / 3000.0) * (exam_influence) + (grade_in_highschool / 5.0) \\\n",
    "            * (1.0 - exam_influence)) * 5.0 + rand_noise\n",
    "grades_y[grades_y < 1] = 1\n",
    "grades_y[grades_y > 5] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iscrtajte ovisnost ciljne vrijednosti (y-os) o prvoj i o drugoj značajki (x-os). Iscrtajte dva odvojena grafa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naučite model L2-regularizirane regresije ($\\lambda = 0.01$), na podacima `grades_X` i `grades_y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sada ponovite gornji eksperiment, ali prvo skalirajte podatke `grades_X` i `grades_y` i spremite ih u varijable `grades_X_fixed` i `grades_y_fixed`. Za tu svrhu, koristite [`StandardScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Gledajući grafikone iz podzadatka (a), koja značajka bi trebala imati veću magnitudu, odnosno važnost pri predikciji prosjeka na studiju? Odgovaraju li težine Vašoj intuiciji? Objasnite.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Multikolinearnost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izradite skup podataka `grades_X_fixed_colinear` tako što ćete u skupu `grades_X_fixed` iz\n",
    "zadatka *7b* duplicirati zadnji stupac (ocjenu iz srednje škole). Time smo efektivno uveli savršenu multikolinearnost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponovno, naučite na ovom skupu L2-regularizirani model regresije ($\\lambda = 0.01$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Usporedite iznose težina s onima koje ste dobili u zadatku *7b*. Što se dogodilo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slučajno uzorkujte 50% elemenata iz skupa `grades_X_fixed_colinear` i naučite dva modela L2-regularizirane regresije, jedan s $\\lambda=0.01$ i jedan s $\\lambda=1000$). Ponovite ovaj pokus 10 puta (svaki put s drugim podskupom od 50% elemenata).  Za svaki model, ispišite dobiveni vektor težina u svih 10 ponavljanja te ispišite standardnu devijaciju vrijednosti svake od težina (ukupno šest standardnih devijacija, svaka dobivena nad 10 vrijednosti)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Kako regularizacija utječe na stabilnost težina?  \n",
    "**Q:** Jesu li koeficijenti jednakih magnituda kao u prethodnom pokusu? Objasnite zašto."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
